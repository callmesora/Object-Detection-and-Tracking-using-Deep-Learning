{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52d9756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'validation' already prepared\n",
      "Loading 'bdd100k' split 'validation'\n",
      " 100% |█████████████| 10000/10000 [3.2m elapsed, 0s remaining, 60.8 samples/s]      \n",
      "Dataset 'bdd100k-validation' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=true&handleId=d49e1ad2-9886-4ea2-b734-41dd0f7e1420\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5b7bf6ef70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# The path to the source files that you manually downloaded\n",
    "source_dir = \"bdd100k/\"\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"bdd100k\",\n",
    "    split=\"validation\",\n",
    "    source_dir=source_dir,\n",
    "    copy_files=False,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501978be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     bdd100k-validation\n",
      "Media type:  image\n",
      "Num samples: 10000\n",
      "Tags:        ['validation']\n",
      "Sample fields:\n",
      "    id:         fiftyone.core.fields.ObjectIdField\n",
      "    filepath:   fiftyone.core.fields.StringField\n",
      "    tags:       fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    weather:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    timeofday:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    scene:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    detections: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "View stages:\n",
      "    ---\n"
     ]
    }
   ],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "view = dataset.view()\n",
    "\n",
    "# Only include samples whose ground truth `label` is \"slug\" or \"conch\"\n",
    "print(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e87e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Dataset description *****\r\n",
      "The Berkeley Deep Drive (BDD) dataset is one of the largest and most\r\n",
      "diverse video datasets for autonomous vehicles.\r\n",
      "\r\n",
      "The BDD100K dataset contains 100,000 video clips collected from more than\r\n",
      "50,000 rides covering New York, San Francisco Bay Area, and other regions.\r\n",
      "The dataset contains diverse scene types such as city streets, residential\r\n",
      "areas, and highways. Furthermore, the videos were recorded in diverse\r\n",
      "weather conditions at different times of the day.\r\n",
      "\r\n",
      "The videos are split into training (70K), validation (10K) and testing\r\n",
      "(20K) sets. Each video is 40 seconds long with 720p resolution and a frame\r\n",
      "rate of 30fps. The frame at the 10th second of each video is annotated for\r\n",
      "image classification, detection, and segmentation tasks.\r\n",
      "\r\n",
      "This version of the dataset contains only the 100K images extracted from\r\n",
      "the videos as described above, together with the image classification,\r\n",
      "detection, and segmentation labels.\r\n",
      "\r\n",
      "In order to load the BDD100K dataset, you must download the source data\r\n",
      "manually. The directory should be organized in the following format::\r\n",
      "\r\n",
      "    source_dir/\r\n",
      "        labels/\r\n",
      "            bdd100k_labels_images_train.json\r\n",
      "            bdd100k_labels_images_val.json\r\n",
      "        images/\r\n",
      "            100k/\r\n",
      "                train/\r\n",
      "                test/\r\n",
      "                val/\r\n",
      "\r\n",
      "You can register at https://bdd-data.berkeley.edu in order to get links to\r\n",
      "download the data.\r\n",
      "\r\n",
      "Example usage::\r\n",
      "\r\n",
      "    import fiftyone as fo\r\n",
      "    import fiftyone.zoo as foz\r\n",
      "\r\n",
      "    # The path to the source files that you manually downloaded\r\n",
      "    source_dir = \"/path/to/dir-with-bdd100k-files\"\r\n",
      "\r\n",
      "    dataset = foz.load_zoo_dataset(\r\n",
      "        \"bdd100k\",\r\n",
      "        split=\"validation\",\r\n",
      "        source_dir=source_dir,\r\n",
      "    )\r\n",
      "\r\n",
      "    session = fo.launch_app(dataset)\r\n",
      "\r\n",
      "Dataset size\r\n",
      "    7.10 GB\r\n",
      "\r\n",
      "Source\r\n",
      "    https://bdd-data.berkeley.edu\r\n",
      "\r\n",
      "Args:\r\n",
      "    source_dir (None): the directory containing the manually downloaded\r\n",
      "        BDD100K files\r\n",
      "    copy_files (True): whether to move (False) or create copies (True) of\r\n",
      "        the source files when populating the dataset directory\r\n",
      "\r\n",
      "***** Tags *****\r\n",
      "image, multilabel, automotive, manual\r\n",
      "\r\n",
      "***** Supported splits *****\r\n",
      "train, validation, test\r\n",
      "\r\n",
      "***** Dataset location *****\r\n",
      "Dataset 'bdd100k' is not downloaded\r\n"
     ]
    }
   ],
   "source": [
    "!fiftyone zoo datasets info bdd100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f0f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 10000/10000 [4.3m elapsed, 0s remaining, 44.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# The Dataset or DatasetView containing the samples you wish to export\n",
    "dataset_or_view = dataset\n",
    "\n",
    "# The directory to which to write the exported dataset\n",
    "export_dir = \"bdd_in_YOLOV5_train_NewL/\"\n",
    "\n",
    "# The name of the sample field containing the label that you wish to export\n",
    "# Used when exporting labeled datasets (e.g., classification or detection)\n",
    "#label_field = \"ground_truth\"  # for example\n",
    "\n",
    "# The type of dataset to export\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\n",
    "dataset_type = fo.types.YOLOv5Dataset  # for example\n",
    "\n",
    "# Export the dataset\n",
    "dataset_or_view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=dataset_type\n",
    "    #export_media=\"copy\",\n",
    "    #label_field=label_field,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320213a3",
   "metadata": {},
   "source": [
    "# Export only specific Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736b6164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'validation' already prepared\n",
      "Loading existing dataset 'bdd100k-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DatasetView has no field 'car'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m foz\u001b[38;5;241m.\u001b[39mload_zoo_dataset(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbdd100k\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     source_dir\u001b[38;5;241m=\u001b[39msource_dir,\n\u001b[1;32m     12\u001b[0m     copy_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdefault_classes))  \u001b[38;5;66;03m# 91\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m view \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/collections.py:3011\u001b[0m, in \u001b[0;36mSampleCollection.filter_labels\u001b[0;34m(self, field, filter, only_matches, trajectories)\u001b[0m\n\u001b[1;32m   2732\u001b[0m \u001b[38;5;129m@view_stage\u001b[39m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_labels\u001b[39m(\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;28mself\u001b[39m, field, \u001b[38;5;28mfilter\u001b[39m, only_matches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, trajectories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m ):\n\u001b[1;32m   2736\u001b[0m     \u001b[38;5;124;03m\"\"\"Filters the :class:`fiftyone.core.labels.Label` field of each\u001b[39;00m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;124;03m    sample in the collection.\u001b[39;00m\n\u001b[1;32m   2738\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;124;03m        a :class:`fiftyone.core.view.DatasetView`\u001b[39;00m\n\u001b[1;32m   3010\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_view_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFilterLabels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m            \u001b[49m\u001b[43monly_matches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_matches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrajectories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/dataset.py:4178\u001b[0m, in \u001b[0;36mDataset._add_view_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m   4177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_view_stage\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage):\n\u001b[0;32m-> 4178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/collections.py:2298\u001b[0m, in \u001b[0;36mSampleCollection.add_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_stage\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage):\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;124;03m\"\"\"Applies the given :class:`fiftyone.core.stages.ViewStage` to the\u001b[39;00m\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;124;03m    collection.\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03m        a :class:`fiftyone.core.view.DatasetView`\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_view_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/view.py:848\u001b[0m, in \u001b[0;36mDatasetView._add_view_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_view_stage\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage):\n\u001b[0;32m--> 848\u001b[0m     \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stage\u001b[38;5;241m.\u001b[39mhas_view:\n\u001b[1;32m    851\u001b[0m         view \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mload_view(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/stages.py:1815\u001b[0m, in \u001b[0;36mFilterLabels.validate\u001b[0;34m(self, sample_collection)\u001b[0m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_collection):\n\u001b[0;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_labels_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_collection\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/stages.py:1742\u001b[0m, in \u001b[0;36mFilterLabels._parse_labels_field\u001b[0;34m(self, sample_collection)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_labels_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_collection):\n\u001b[0;32m-> 1742\u001b[0m     field_name, is_list_field, is_frame_field \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_labels_field\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_field\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_frame_field \u001b[38;5;241m=\u001b[39m is_frame_field\n\u001b[1;32m   1746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels_field \u001b[38;5;241m=\u001b[39m field_name\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/stages.py:6080\u001b[0m, in \u001b[0;36m_parse_labels_field\u001b[0;34m(sample_collection, field_path)\u001b[0m\n\u001b[1;32m   6079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_labels_field\u001b[39m(sample_collection, field_path):\n\u001b[0;32m-> 6080\u001b[0m     label_type \u001b[38;5;241m=\u001b[39m \u001b[43msample_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_field_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6081\u001b[0m     is_frame_field \u001b[38;5;241m=\u001b[39m sample_collection\u001b[38;5;241m.\u001b[39m_is_frame_field(field_path)\n\u001b[1;32m   6082\u001b[0m     is_list_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28missubclass\u001b[39m(label_type, fol\u001b[38;5;241m.\u001b[39m_LABEL_LIST_FIELDS)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/core/collections.py:7281\u001b[0m, in \u001b[0;36mSampleCollection._get_label_field_type\u001b[0;34m(self, field_name)\u001b[0m\n\u001b[1;32m   7279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m schema:\n\u001b[1;32m   7280\u001b[0m     ftype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe field\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_frame_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 7281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   7282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has no \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7283\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, ftype, field_name)\n\u001b[1;32m   7284\u001b[0m     )\n\u001b[1;32m   7286\u001b[0m field \u001b[38;5;241m=\u001b[39m schema[field_name]\n\u001b[1;32m   7288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(field, fof\u001b[38;5;241m.\u001b[39mEmbeddedDocumentField) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\n\u001b[1;32m   7289\u001b[0m     field\u001b[38;5;241m.\u001b[39mdocument_type, fol\u001b[38;5;241m.\u001b[39mLabel\n\u001b[1;32m   7290\u001b[0m ):\n",
      "\u001b[0;31mValueError\u001b[0m: DatasetView has no field 'car'"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# The path to the source files that you manually downloaded\n",
    "source_dir = \"bdd100k/\"\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"bdd100k\",\n",
    "    split=\"validation\",\n",
    "    source_dir=source_dir,\n",
    "    copy_files=False,\n",
    ")\n",
    "\n",
    "print(len(dataset.default_classes))  # 91\n",
    "view = dataset.filter_labels(\"car\", F(\"label\").is_in([\"car\"]))\n",
    "\n",
    "\n",
    "#session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd7607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/pedro/fiftyone/coco-2017/validation' if necessary\n",
      "Downloading annotations to '/home/pedro/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      "   0% |\\-----|    7.5Mb/1.9Gb [7.8s elapsed, 33.2m remaining, 1022.1Kb/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfiftyone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViewField \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load 10 samples containing cats and dogs (among other objects)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfoz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_zoo_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco-2017\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Loading zoo datasets generally populates the `default_classes` attribute\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdefault_classes))  \u001b[38;5;66;03m# 91\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:197\u001b[0m, in \u001b[0;36mload_zoo_dataset\u001b[0;34m(name, split, splits, label_field, dataset_name, dataset_dir, download_if_necessary, drop_existing_dataset, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     zoo_dataset_cls \u001b[38;5;241m=\u001b[39m _get_zoo_dataset_cls(name)\n\u001b[1;32m    193\u001b[0m     download_kwargs, _ \u001b[38;5;241m=\u001b[39m fou\u001b[38;5;241m.\u001b[39mextract_kwargs_for_class(\n\u001b[1;32m    194\u001b[0m         zoo_dataset_cls, kwargs\n\u001b[1;32m    195\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m     info, dataset_dir \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_zoo_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     zoo_dataset \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mget_zoo_dataset()\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:116\u001b[0m, in \u001b[0;36mdownload_zoo_dataset\u001b[0;34m(name, split, splits, dataset_dir, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"Downloads the dataset of the given name from the FiftyOne Dataset Zoo.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mAny dataset splits that already exist in the specified directory are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    -   dataset_dir: the directory containing the dataset\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m zoo_dataset, dataset_dir \u001b[38;5;241m=\u001b[39m _parse_dataset_details(\n\u001b[1;32m    114\u001b[0m     name, dataset_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    115\u001b[0m )\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzoo_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:1004\u001b[0m, in \u001b[0;36mZooDataset.download_and_prepare\u001b[0;34m(self, dataset_dir, split, splits, overwrite, cleanup)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading split \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    995\u001b[0m         split,\n\u001b[1;32m    996\u001b[0m         split_dir,\n\u001b[1;32m    997\u001b[0m         suffix,\n\u001b[1;32m    998\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m (\n\u001b[1;32m   1001\u001b[0m     dataset_type,\n\u001b[1;32m   1002\u001b[0m     num_samples,\n\u001b[1;32m   1003\u001b[0m     classes,\n\u001b[0;32m-> 1004\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscratch_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# Add split to ZooDatasetInfo\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/base.py:1131\u001b[0m, in \u001b[0;36mCOCO2017Dataset._download_and_prepare\u001b[0;34m(self, dataset_dir, scratch_dir, split)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_dir, scratch_dir, split):\n\u001b[0;32m-> 1131\u001b[0m     num_samples, classes, downloaded \u001b[38;5;241m=\u001b[39m \u001b[43mfouc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_coco_dataset_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2017\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_raw_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscratch_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscratch_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m     dataset_type \u001b[38;5;241m=\u001b[39m fot\u001b[38;5;241m.\u001b[39mCOCODetectionDataset()\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m downloaded:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/utils/coco.py:1544\u001b[0m, in \u001b[0;36mdownload_coco_dataset_split\u001b[0;34m(dataset_dir, split, year, label_types, classes, image_ids, num_workers, shuffle, seed, max_samples, raw_dir, scratch_dir)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(full_anno_path):\n\u001b[1;32m   1543\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, anno_type, zip_path)\n\u001b[0;32m-> 1544\u001b[0m     \u001b[43metaw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1546\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, anno_type, full_anno_path)\n\u001b[1;32m   1547\u001b[0m     etau\u001b[38;5;241m.\u001b[39mextract_zip(zip_path, outdir\u001b[38;5;241m=\u001b[39munzip_dir, delete_zip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:67\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, path, chunk_size, verify, quiet)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"Downloads a file from a URL. If a path is specified, the file is written\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mthere. Otherwise, the content is returned as a binary string.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    WebSessionError: if the download failed\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m sess \u001b[38;5;241m=\u001b[39m WebSession(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, verify\u001b[38;5;241m=\u001b[39mverify, quiet\u001b[38;5;241m=\u001b[39mquiet)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;28;01melse\u001b[39;00m sess\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:150\u001b[0m, in \u001b[0;36mWebSession.write\u001b[0;34m(self, path, url, params)\u001b[0m\n\u001b[1;32m    148\u001b[0m etau\u001b[38;5;241m.\u001b[39mensure_basedir(path)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:172\u001b[0m, in \u001b[0;36mWebSession._do_download\u001b[0;34m(self, r, f)\u001b[0m\n\u001b[1;32m    168\u001b[0m size_bits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m size_bytes \u001b[38;5;28;01mif\u001b[39;00m size_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m etau\u001b[38;5;241m.\u001b[39mProgressBar(\n\u001b[1;32m    170\u001b[0m     size_bits, use_bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquiet\n\u001b[1;32m    171\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pb:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size):\n\u001b[1;32m    173\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m    174\u001b[0m         pb\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:750\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 750\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    751\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:564\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 564\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    567\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    509\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[1;32m    510\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:455\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 455\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:499\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    494\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# The path to the source files that you manually downloaded\n",
    "source_dir = \"bdd100k/\"\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"bdd100k\",\n",
    "    split=\"validation\",\n",
    "    source_dir=source_dir,\n",
    "    copy_files=False,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)\n",
    "\n",
    "\n",
    "# Load 10 samples containing cats and dogs (among other objects)\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    classes=[\"cat\", \"dog\"],\n",
    "    shuffle=True,\n",
    "    max_samples=10,\n",
    ")\n",
    "\n",
    "# Loading zoo datasets generally populates the `default_classes` attribute\n",
    "print(len(dataset.default_classes))  # 91\n",
    "\n",
    "# Create a view that only contains cats and dogs\n",
    "view = dataset.filter_labels(\"ground_truth\", F(\"label\").is_in([\"cat\", \"dog\"]))\n",
    "\n",
    "# By default, `default_classes` will be used to populate the COCO categories\n",
    "view.export(\n",
    "    labels_path=\"/tmp/coco1.json\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    ")\n",
    "\n",
    "# But, since we're only interested in exporting cats and dogs, we can override\n",
    "# this by manually providing the `classes` argument\n",
    "view.export(\n",
    "    labels_path=\"/tmp/coco2.json\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    classes=[\"cat\", \"dog\"],\n",
    ")\n",
    "\n",
    "# Equivalently, we can clear `default_classes` first so that the observed\n",
    "# labels (only cats and dogs in this case) will be used\n",
    "dataset.default_classes = None\n",
    "view.export(\n",
    "    labels_path=\"/tmp/coco3.json\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715662a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
